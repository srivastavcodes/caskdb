package cask

import (
	"encoding/binary"
	"errors"
	"fmt"
	"io"
	"log/slog"
	"math"
	"os"
	"path/filepath"

	wal "github.com/srivastavcodes/write-ahead-log"
)

const (
	MergeDirSuffixName   = "-merge"
	MergeFinishedBatchId = 0
)

func (cdb *CaskDb) Merge(reopen bool) error {
	return nil
}

// openMergeDb creates and opens a new CaskDb instance in a temporary merge directory
// for compaction operations. It removes any existing merge directory, configures the
// database with sync disabled for performance, and opens a hint file to track the new
// positions of merged data. Closing the db is on the caller.
func (cdb *CaskDb) openMergeDb() (*CaskDb, error) {
	mdir := mergeDirPath(cdb.opts.DirPath)

	// remove the merge dir if it exists
	if err := os.RemoveAll(mdir); err != nil {
		return nil, err
	}
	opts := cdb.opts
	// we don't need the origin sync policy because we can sync the data
	// manually after the merge is complete.
	opts.Sync, opts.BytesPerSync = false, 0
	opts.DirPath = mdir

	mergedb, err := Open(opts)
	if err != nil {
		return nil, err
	}
	// open the hint file to write the new position of the data
	hintFile, err := wal.Open(wal.Options{
		// hint files are written once during merge and read in full on
		// startup; so disable seg rotation by setting an effectively
		// infinite segment size.
		//
		// NOTE: not the actual size of the file, but a limit determining
		// when to rotate the seg file; in this case, never
		SegmentSize:    math.MaxInt64,
		DirPath:        opts.DirPath,
		Sync:           false,
		BytesPerSync:   0,
		SegmentFileExt: hintFileNameSuffix,
	})
	if err != nil {
		return nil, err
	}
	mergedb.hintFile = hintFile
	return mergedb, nil
}

// loadIndexFromHintFile reads hint records from the hint file and rebuilds the in-memory
// index with key-position mappings. Hint files are generated during merge operations to
// enable fast startup by avoiding a full scan of data files. Returns an error if the hint
// file cannot be opened or if reading fails (except for EOF which indicates completion).
func (cdb *CaskDb) loadIndexFromHintFile() error {
	hintFile, err := wal.Open(wal.Options{
		SegmentSize:    math.MaxInt64,
		DirPath:        cdb.opts.DirPath,
		SegmentFileExt: hintFileNameSuffix,
	})
	if err != nil {
		return err
	}
	defer func() { _ = hintFile.Close() }()

	reader := hintFile.NewReader()
	hintFile.SetIsStartupTraversal(true)

	// read all the hint records from the hint file.
	for {
		encRec, _, err := reader.Next()
		if err != nil {
			if errors.Is(err, io.EOF) {
				break
			}
			return err
		}
		key, pos := decodeHintRecord(encRec)
		// putting it directly into the index without checking because
		// the hint records are generated by the merge operations and
		// are known to be valid (cause if they ain't...hehe, shit's gonna blow up).
		cdb.index.Put(key, pos)
	}
	hintFile.SetIsStartupTraversal(false)
	return nil
}

// loadMergeFiles loads all the merge files and copies the data to the original data
// directory. If there are no merge files, or the merge operation is not completed
// yet, it will return nil.
func loadMergeFiles(dirPath string) error {
	mdir := mergeDirPath(dirPath)

	if _, err := os.Stat(mdir); err != nil {
		if os.IsNotExist(err) {
			return nil
		}
		return err
	}
	defer func() { _ = os.RemoveAll(mdir) }()

	copyFile := func(suffix string, fileId uint32, force bool) {
		srcFile := wal.SegmentFileName(mdir, suffix, fileId)

		info, err := os.Stat(srcFile)
		if err != nil {
			if os.IsNotExist(err) {
				return
			}
			panic(fmt.Sprintf(
				"loadMergeFiles: failed to stat src file %s: %v",
				srcFile, err,
			))
		}
		if !force && info.Size() == 0 {
			return
		}
		dstFile := wal.SegmentFileName(dirPath, suffix, fileId)
		// workingDir/dbdir-merge/000000001.SEG -> workingDir/dbdir/000000001.SEG
		if err = os.Rename(srcFile, dstFile); err != nil {
			slog.Error(fmt.Sprintf("loadMergeFiles-copyFile: failed to rename %s to %s: %v",
				srcFile, dstFile, err,
			))
		}
	}
	watermarkedSegId, err := getCompactionWatermark(mdir)
	if err != nil {
		return err
	}
	// now we have the watermarked segment id, so all the segment files with id
	// lesser than that should be moved to the original data directory, and the
	// original data files should be deleted.
	for id := uint32(1); id <= watermarkedSegId; id++ {
		dstFile := wal.SegmentFileName(dirPath, dataFileNameSuffix, id)
		// remove the original data file
		if _, err = os.Stat(dstFile); nil == err {
			if err = os.Remove(dstFile); err != nil {
				return err
			}
		}
		// move the merge data file to the original data directory.
		copyFile(dataFileNameSuffix, id, false)
	}
	// copy merge and hint files to the original data directory; there is only
	// one merge file, so the id is always 1, the same as the hint file.
	copyFile(watermarkedFileExt, 1, true)
	copyFile(hintFileNameSuffix, 1, true)
	return nil
}

// getCompactionWatermark reads and returns the compaction watermark segment ID
// from the merge directory. The watermark indicates the last segment that was
// successfully processed during a merge operation.
//
// It reads the segment ID from the compaction watermark file in the specified
// mergePath. If the file doesn't exist, it returns 0 with no error, indicating
// no prior merge operation. The segment ID is stored as a 4-byte little-endian
// unsigned integer after a 7-byte chunk header.
func getCompactionWatermark(mergePath string) (wal.SegmentId, error) {
	const chunkHeaderSize int64 = 7
	// check if the merge operation is completed
	cwFile, err := os.Open(wal.SegmentFileName(mergePath, watermarkedFileExt, 1))
	if err != nil {
		return 0, nil
	}
	defer func() { _ = cwFile.Close() }()
	// only 4 bytes are needed to store the segment id and the bytes
	// skipped are headers.
	cwBuf := make([]byte, 4)
	if _, err = cwFile.ReadAt(cwBuf, chunkHeaderSize); err != nil {
		return 0, err
	}
	segId := binary.LittleEndian.Uint32(cwBuf)
	return segId, nil
}

// mergeDirPath concatenates the MergeDirSuffixName into the base of dirPath and
// returns the new path.
// eg: dirPath = working/dbdir; returns working/dbdir-merge
func mergeDirPath(dirPath string) string {
	dirP := filepath.Dir(dirPath)
	base := filepath.Base(dirPath)
	return filepath.Join(dirP, base+MergeDirSuffixName)
}

func positionEqual(a, b *wal.ChunkPosition) bool {
	return a.SegmentId == b.SegmentId &&
		a.BlockNumber == b.BlockNumber && a.ChunkOffset == b.ChunkOffset
}
